{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import diffusion_dist as diff\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import decomposition, preprocessing\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import model.autoencoder as ae\n",
    "\n",
    "from dataset import hhRNA1, hhATAC1\n",
    "\n",
    "from utils import *\n",
    "from model.loss import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "symsim_r1b1 = hhRNA1(standardize=False, rna_seq_file = \"./data/human_hematopoiesis/count_rna.csv\", rna_celltype_file = \"./data/human_hematopoiesis/celltypes_rna.txt\")\n",
    "symsim_r1b2 = hhATAC1(standardize=False, atac_seq_file = \"./data/human_hematopoiesis/count_atac.csv\", atac_celltype_file = \"./data/human_hematopoiesis/celltypes_atac.txt\")\n",
    "\n",
    "symsim_r1b1_CONFIG = { \n",
    "    'in_features': 500,\n",
    "    'layers': [512, 256, 128, 2], # number of nodes in each layer of encoder and decoder.\n",
    "    'minibatch_size': 32,\n",
    "    'use_batchnorm': True, # use batch normalization layer.\n",
    "    'use_tanh': False, # tanh before latent visualization.\n",
    "}\n",
    "\n",
    "symsim_r1b2_CONFIG = { \n",
    "    'in_features': 1764,\n",
    "    'layers': [512, 256, 128, 2], # number of nodes in each layer of encoder and decoder.\n",
    "    'minibatch_size': 32,\n",
    "    'use_batchnorm': True, # use batch normalization layer.\n",
    "    'use_tanh': False, # tanh before latent visualization.\n",
    "}\n",
    "\n",
    "\n",
    "train_r1b1_loader = DataLoader(symsim_r1b1, batch_size = symsim_r1b1_CONFIG[\"minibatch_size\"], shuffle = True)\n",
    "train_r1b2_loader = DataLoader(symsim_r1b2, batch_size = symsim_r1b2_CONFIG[\"minibatch_size\"], shuffle = True)\n",
    "test_r1b1_loader = DataLoader(symsim_r1b1, batch_size = len(symsim_r1b1), shuffle = False)\n",
    "test_r1b2_loader = DataLoader(symsim_r1b2, batch_size = len(symsim_r1b2), shuffle = False)\n",
    "\n",
    "for data in test_r1b1_loader:\n",
    "    Diff1 = diff.phate_similarity(data[\"raw\"], \n",
    "                                  n_neigh = 5, \n",
    "                                  t = 8, \n",
    "                                  use_potential = True)\n",
    "    \n",
    "    DPT1 = diff.DPT_similarity(data[\"raw\"], \n",
    "                               n_neigh = 5, \n",
    "                               use_potential = True)\n",
    "    \n",
    "    Diff1 = torch.FloatTensor(Diff1).to(device)\n",
    "    \n",
    "    DPT1 = torch.FloatTensor(DPT1).to(device)\n",
    "\n",
    "\n",
    "for data in test_r1b2_loader:\n",
    "    Diff2 = diff.phate_similarity(data[\"raw\"], \n",
    "                                  n_neigh = 5, \n",
    "                                  t = 8, \n",
    "                                  use_potential = True)\n",
    "    \n",
    "    DPT2 = diff.DPT_similarity(data[\"raw\"], \n",
    "                               n_neigh = 5, \n",
    "                               use_potential = True)\n",
    "    \n",
    "    Diff2 = torch.FloatTensor(Diff2).to(device)\n",
    "    \n",
    "    DPT2 = torch.FloatTensor(DPT2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unpaired(model_rna, model_atac, disc, data_loader_rna, data_loader_atac, diff_sim_rna, diff_sim_atac, optimizer_rna, optimizer_atac, optimizer_D, n_epochs = 50, lamb_r = 1, lamb_d = 1):\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        iteration = max(len(data_loader_rna), len(data_loader_atac))\n",
    "        for data in zip(data_loader_rna, data_loader_atac):\n",
    "            # Update RNA Encoder\n",
    "            data_rna, data_atac = data\n",
    "            batch_cols_rna = data_rna['index'].to(device)\n",
    "            batch_sim_rna = diff_sim_rna[batch_cols_rna,:][:,batch_cols_rna]\n",
    "            batch_expr_rna = data_rna['count'].to(device)\n",
    "\n",
    "            batch_expr_r_rna = model_rna(batch_expr_rna)\n",
    "            z_rna = model_rna[:1](batch_expr_rna)\n",
    "#             traj_loss(recon_x, x, z, diff_sim, lamb_recon = 1, lamb_dist = 1, recon_mode = \"original\")\n",
    "            train_loss_rna, loss_recon_rna, loss_dist_rna = traj_loss(recon_x = batch_expr_r_rna, x = batch_expr_rna, z = z_rna, diff_sim = batch_sim_rna, lamb_recon = lamb_r, lamb_dist = lamb_d, recon_mode = \"relative\")\n",
    "\n",
    "            train_loss_rna.backward()\n",
    "            optimizer_rna.step()\n",
    "            optimizer_rna.zero_grad()\n",
    "\n",
    "            # Update ATAC Encoder\n",
    "            batch_cols_atac = data_atac['index'].to(device)\n",
    "            batch_sim_atac = diff_sim_atac[batch_cols_atac,:][:,batch_cols_atac]\n",
    "            batch_expr_atac = data_atac['count'].to(device)\n",
    "\n",
    "            batch_expr_r_atac = model_atac(batch_expr_atac)\n",
    "            z_atac = model_atac[:1](batch_expr_atac)\n",
    "\n",
    "            train_loss_atac, loss_recon_atac, loss_dist_atac = traj_loss(recon_x = batch_expr_r_atac, x = batch_expr_atac, z = z_atac, diff_sim = batch_sim_atac, lamb_recon = lamb_r, lamb_dist = lamb_d, recon_mode = \"relative\")\n",
    "\n",
    "            train_loss_atac.backward()\n",
    "            optimizer_atac.step()\n",
    "            optimizer_atac.zero_grad()\n",
    "\n",
    "            # need to go through all the calculation again since the encoder has been updated, ERROR shows up in pytorch 1.5 and above.\n",
    "            # see: https://github.com/pytorch/pytorch/issues/39141 \n",
    "            z_rna = model_rna[:1](batch_expr_rna)\n",
    "            z_atac = model_atac[:1](batch_expr_atac)\n",
    "\n",
    "            # Update Discriminator\n",
    "            D_loss_avg = 0\n",
    "            n_iter = 15\n",
    "            n_rna = batch_cols_rna.shape[0]\n",
    "            n_atac = batch_cols_atac.shape[0]\n",
    "            # note that detach here is necessary, use directly will cause error in encoder update later\n",
    "            input_disc = torch.cat((z_rna.detach(), z_atac.detach()), dim = 0)\n",
    "            target = torch.cat((torch.full((n_rna, ), 0, dtype = torch.float), torch.full((n_atac, ), 1, dtype = torch.float))).to(device)\n",
    "            \n",
    "\n",
    "            for i in range(n_iter):\n",
    "                output = disc(input_disc).squeeze()\n",
    "                D_loss = F.binary_cross_entropy(output, target)\n",
    "                D_loss_avg += D_loss.item()\n",
    "                D_loss.backward()\n",
    "                optimizer_D.step()\n",
    "                optimizer_D.zero_grad()\n",
    "            D_loss_avg /= n_iter\n",
    "\n",
    "            # Update Encoder\n",
    "            E_loss = -1 * F.binary_cross_entropy(disc(torch.cat((z_rna, z_atac), dim = 0)).squeeze(), target)\n",
    "            E_loss.backward()\n",
    "            optimizer_rna.step()\n",
    "            optimizer_atac.step()\n",
    "            optimizer_rna.zero_grad()\n",
    "            optimizer_atac.zero_grad()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            log_rna = \"RNA loss: {:.5f}, RNA recon loss: {:.5f}, RNA dist loss: {:.5f}\".format(train_loss_rna.item(), loss_recon_rna.item(), loss_dist_rna.item())\n",
    "            log_atac = \"ATAC loss: {:.5f}, ATAC recon loss: {:.5f}, ATAC dist loss: {:.5f}\".format(train_loss_atac.item(), loss_recon_atac.item(), loss_dist_atac.item())\n",
    "            log_D = \"Discriminator loss: {:.5f}\".format(D_loss_avg)\n",
    "            print(\"epoch: \", epoch, log_rna, log_atac, log_D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "ae1 = nn.Sequential(OrderedDict([\n",
    "        (\"encoder\", ae.Encoder(symsim_r1b1_CONFIG)), \n",
    "        (\"decoder\", ae.Decoder(symsim_r1b1_CONFIG))\n",
    "      ])).to(device)\n",
    "\n",
    "ae2 = nn.Sequential(OrderedDict([\n",
    "        (\"encoder\", ae.Encoder(symsim_r1b2_CONFIG)), \n",
    "        (\"decoder\", ae.Decoder(symsim_r1b2_CONFIG))\n",
    "      ])).to(device)\n",
    "\n",
    "disc = ae.discriminator().to(device)\n",
    "\n",
    "optimizer_rna = torch.optim.Adam(ae1.parameters(), lr = 5e-4)\n",
    "optimizer_atac = torch.optim.Adam(ae2.parameters(), lr = 5e-4)\n",
    "optimizer_D = torch.optim.Adam(disc.parameters(), lr = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch:  0 RNA loss: -0.68074, RNA recon loss: 0.25776, RNA dist loss: -0.93850 ATAC loss: -0.71620, ATAC recon loss: 0.19212, ATAC dist loss: -0.90832 Discriminator loss: 0.64710\n",
      "epoch:  10 RNA loss: -0.77497, RNA recon loss: 0.19125, RNA dist loss: -0.96622 ATAC loss: -0.89289, ATAC recon loss: 0.08213, ATAC dist loss: -0.97502 Discriminator loss: 0.63528\n",
      "epoch:  20 RNA loss: -0.79050, RNA recon loss: 0.17781, RNA dist loss: -0.96831 ATAC loss: -0.89800, ATAC recon loss: 0.07461, ATAC dist loss: -0.97261 Discriminator loss: 0.70070\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-4c274804d911>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_unpaired\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mae1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mae2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_r1b1_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_r1b2_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDiff1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDiff2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m151\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlamb_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlamb_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-6bdd93b4cf13>\u001b[0m in \u001b[0;36mtrain_unpaired\u001b[1;34m(model_rna, model_atac, disc, data_loader_rna, data_loader_atac, diff_sim_rna, diff_sim_atac, n_epochs, lamb_r, lamb_d)\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0mD_loss_avg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mD_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[0mD_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                 \u001b[0moptimizer_D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m                 \u001b[0moptimizer_D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mD_loss_avg\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m                    )\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_unpaired(ae1, ae2, disc, train_r1b1_loader, train_r1b2_loader, Diff1, Diff2, n_epochs=151, lamb_r = 1, lamb_d = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     'ae1': ae1.state_dict(),\n",
    "#     'optim_ae1': optimizer_rna.state_dict(),\n",
    "#     'ae2': ae2.state_dict(),\n",
    "#     'optim_ae2': optimizer_rna.state_dict(),\n",
    "#     'disc': disc.state_dict(),\n",
    "#     'optim_disc': optimizer_D.state_dict(),\n",
    "#     'config1': symsim_r1b1_CONFIG,\n",
    "#     'config2': symsim_r1b2_CONFIG\n",
    "# }, './saved_model/hm_phate_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = torch.load('./saved_model/hm_phate.pt')\n",
    "\n",
    "# ae1 = nn.Sequential(OrderedDict([\n",
    "#         (\"encoder\", ae.Encoder(symsim_r1b1_CONFIG)), \n",
    "#         (\"decoder\", ae.Decoder(symsim_r1b1_CONFIG))\n",
    "#       ])).to(device)\n",
    "# ae1.load_state_dict(state['ae1'])\n",
    "\n",
    "# ae2 = nn.Sequential(OrderedDict([\n",
    "#         (\"encoder\", ae.Encoder(symsim_r1b2_CONFIG)), \n",
    "#         (\"decoder\", ae.Decoder(symsim_r1b2_CONFIG))\n",
    "#       ])).to(device)\n",
    "# ae2.load_state_dict(state['ae2'])\n",
    "\n",
    "# disc = ae.discriminator().to(device)\n",
    "# disc.load_state_dict(state['disc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae1.eval()\n",
    "ae2.eval()\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "for data in test_r1b1_loader:\n",
    "    ae_coordinates = ae1[:1](data['count'].to(device)).cpu().detach().numpy()\n",
    "cell_type = symsim_r1b1.cell_labels\n",
    "cluster_types = np.unique(cell_type)\n",
    "colormap = plt.cm.get_cmap(\"tab20\", cluster_types.shape[0])\n",
    "\n",
    "for i, cluster_type in enumerate(cluster_types):\n",
    "    index = np.where(cell_type == cluster_type)[0]\n",
    "    ax.scatter(ae_coordinates[index,0], ae_coordinates[index,1], color = colormap(i), alpha = 1)\n",
    "\n",
    "\n",
    "for data in test_r1b2_loader:\n",
    "    ae_coordinates = ae2[:1](data['count'].to(device)).cpu().detach().numpy()\n",
    "cell_type = symsim_r1b2.cell_labels\n",
    "cluster_types = np.unique(cell_type)\n",
    "colormap = plt.cm.get_cmap(\"tab20\", cluster_types.shape[0])\n",
    "\n",
    "for i, cluster_type in enumerate(cluster_types):\n",
    "    index = np.where(cell_type == cluster_type)[0]\n",
    "    ax.scatter(ae_coordinates[index,0], ae_coordinates[index,1], color = colormap(i), alpha = 1)\n",
    "\n",
    "ax.legend(cluster_types)\n",
    "# fig.savefig(\"./result/hm/phate_backbones_2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae1.eval()\n",
    "ae2.eval()\n",
    "fig = plt.figure(figsize = (20,7))\n",
    "axs = fig.subplots(1,2)\n",
    "\n",
    "for data in test_r1b1_loader:\n",
    "    ae_coordinates = ae1[:1](data['count'].to(device)).cpu().detach().numpy()\n",
    "cell_type = symsim_r1b1.cell_labels\n",
    "cluster_types = np.unique(cell_type)\n",
    "colormap = plt.cm.get_cmap(\"tab20\", cluster_types.shape[0])\n",
    "\n",
    "for i, cluster_type in enumerate(cluster_types):\n",
    "    index = np.where(cell_type == cluster_type)[0]\n",
    "    axs[0].scatter(ae_coordinates[index,0], ae_coordinates[index,1], color = colormap(i), alpha = 1)\n",
    "axs[0].legend(cluster_types)\n",
    "\n",
    "for data in test_r1b2_loader:\n",
    "    ae_coordinates = ae2[:1](data['count'].to(device)).cpu().detach().numpy()\n",
    "cell_type = symsim_r1b2.cell_labels\n",
    "cluster_types = np.unique(cell_type)\n",
    "colormap = plt.cm.get_cmap(\"tab20\", cluster_types.shape[0])\n",
    "\n",
    "for i, cluster_type in enumerate(cluster_types):\n",
    "    index = np.where(cell_type == cluster_type)[0]\n",
    "    axs[1].scatter(ae_coordinates[index,0], ae_coordinates[index,1], color = colormap(i), alpha = 1)\n",
    "\n",
    "axs[1].legend(cluster_types)\n",
    "# fig.savefig(\"./result/hm/phate_backbones_seperate_2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae1.eval()\n",
    "ae2.eval()\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "ax = fig.add_subplot()\n",
    "colormap = plt.cm.get_cmap(\"Paired\")\n",
    "\n",
    "for data in test_r1b1_loader:\n",
    "    ae_coordinates = ae1[:1](data['count'].to(device)).cpu().detach().numpy()\n",
    "\n",
    "ax.scatter(ae_coordinates[:,0], ae_coordinates[:,1], color = colormap(1), label = \"batch1\", alpha = 1)\n",
    "\n",
    "for data in test_r1b2_loader:\n",
    "    ae_coordinates = ae2[:1](data['count'].to(device)).cpu().detach().numpy()\n",
    "ax.scatter(ae_coordinates[:,0], ae_coordinates[:,1], color = colormap(2), label = \"batch2\", alpha = 1)\n",
    "\n",
    "ax.legend()\n",
    "# fig.savefig(\"./result/hm/phate_backbones_merge_2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model.autoencoder import AutoEncoder\n",
    "# from model.vae import aligned_vae, vae\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import diffusion_dist as diff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from dataset import *\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "# from model.gae import gnn_vae, aligned_gvae, aligned_gae, GraphConvolutionSage\n",
    "\n",
    "# from model.gae import GraphConvolutionSage\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "from model.loss import gae_loss, gvae_loss\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class gnn_ae(nn.Module):\n",
    "    def __init__(self, input_feat_dim, hidden_dim1, hidden_dim2, hidden_dim3, dropout = 0.):\n",
    "        super(gnn_ae, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolutionSage(input_feat_dim, hidden_dim1, dropout)\n",
    "        # the later two layers with activation linear\n",
    "        self.gc2 = GraphConvolutionSage(hidden_dim1, hidden_dim2, dropout)\n",
    "\n",
    "        # final layer can be either graph conv or linear\n",
    "#         self.gc3 = GraphConvolutionSage(hidden_dim2, hidden_dim3, dropout)\n",
    "        \n",
    "        self.dc = pairwiseDistDecoder(dropout)\n",
    "\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.gc1.reset_parameters()\n",
    "        self.gc2.reset_parameters()\n",
    "#         self.gc3.reset_parameters()\n",
    "\n",
    "\n",
    "    def encode(self, x, adj):\n",
    "        # N * hidden_dim1\n",
    "        hidden1 = self.gc2(self.gc1(x, adj), adj)\n",
    "        # mean and variance of the dimension N * hidden_dim2\n",
    "#         return self.gc3(hidden1, adj)\n",
    "        return hidden1\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        z = self.encode(x, adj)      \n",
    "        adj_recon = self.dc(z)\n",
    "        return adj_recon, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolutionSage(nn.Module):\n",
    "    \"\"\"\n",
    "    GraphSAGE\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, dropout=0.):\n",
    "        super(GraphConvolutionSage, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.weight_neigh = Parameter(torch.FloatTensor(out_features, out_features))\n",
    "        self.weight_self = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.weight_support = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.weight_linear = Parameter(torch.FloatTensor(out_features, out_features))\n",
    "\n",
    "\n",
    "        # with dimension (1, out_features), with broadcast -> (N, Dout)\n",
    "        self.bias_support = Parameter(torch.FloatTensor(1, out_features))\n",
    "        self.bias_linear = Parameter(torch.FloatTensor(1, out_features))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.weight_neigh)\n",
    "        torch.nn.init.xavier_uniform_(self.weight_self)\n",
    "        torch.nn.init.xavier_uniform_(self.weight_support)\n",
    "        torch.nn.init.xavier_uniform_(self.weight_linear)\n",
    "\n",
    "        # initialization requires two dimension\n",
    "        torch.nn.init.xavier_uniform_(self.bias_support)\n",
    "        torch.nn.init.xavier_uniform_(self.bias_linear)\n",
    "        \n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        # first dropout some inputs\n",
    "        input = F.dropout(input, self.dropout, self.training)\n",
    "\n",
    "        # Message: two ways\n",
    "        support = F.sigmoid(torch.mm(input, self.weight_support) + self.bias_support)\n",
    "\n",
    "        # Aggregation:\n",
    "        # addition here, could try element-wise max, make diagonal position 0\n",
    "        output = torch.mm(adj, support)\n",
    "\n",
    "        # Update: \n",
    "        # output of dimension N * Dout, \n",
    "        # tried tanh and relu, not very good result, add one linear layer\n",
    "        output = F.relu(torch.mm(output, self.weight_neigh) + torch.mm(input, self.weight_self))\n",
    "        # output = torch.mm(output, self.weight_linear) + self.bias_linear\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class curr_gae(nn.Module):\n",
    "    def __init__(self, feature1_dim, feature2_dim, hidden_dim1, hidden_dim2, hidden_dim3, dropout = 0.):\n",
    "        super(curr_gae, self).__init__()\n",
    "\n",
    "        self.gae1 = gnn_ae(feature1_dim, hidden_dim1, hidden_dim2, hidden_dim3, dropout = dropout)\n",
    "        self.gae2 = gnn_ae(feature2_dim, hidden_dim1, hidden_dim2, hidden_dim3, dropout=dropout)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.gae1.reset_parameters()\n",
    "        self.gae2.reset_parameters()\n",
    "\n",
    "    def forward(self, x1, x2, adj1, adj2):\n",
    "        adj_recon1, z1 = self.gae1(x1, adj1)\n",
    "        adj_recon2, z2 = self.gae2(x2, adj2)\n",
    "                \n",
    "        return adj_recon1, adj_recon2, z1, z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class pairwiseDistDecoder(nn.Module):\n",
    "    \"\"\"Decoder for using pair-wise distance for prediction.\"\"\"\n",
    "\n",
    "    def __init__(self, dropout):\n",
    "        super(pairwiseDistDecoder, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = F.dropout(z, self.dropout, training=self.training)\n",
    "        x_norm = (z**2).sum(1).view(-1, 1)\n",
    "        y_norm = x_norm.view(1, -1)\n",
    "        dist = x_norm + y_norm - 2.0 * torch.mm(z, torch.transpose(z, 0, 1))\n",
    "\n",
    "        return dist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atac_dataset_diffmap = graphdata('./data/expr_atac_processed.csv', k = 20,  diff = \"diffmap\")\n",
    "# rna_dataset_diffmap = graphdata('./data/expr_rna_processed.csv', k = 20, diff=\"diffmap\")\n",
    "# torch.save(atac_dataset_diffmap, f= \"./data/atac_diffmap.pt\")\n",
    "# torch.save(rna_dataset_diffmap, f = \"./data/rna_diffmap.pt\")\n",
    "atac_dataset_diffmap = torch.load(f = \"./data/atac_diffmap.pt\")\n",
    "rna_dataset_diffmap = torch.load(f = \"./data/rna_diffmap.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atac_dataset_dpt = graphdata('./data/expr_atac_processed.csv', k = 20,  diff = \"dpt\")\n",
    "# rna_dataset_dpt = graphdata('./data/expr_rna_processed.csv', k = 20, diff=\"dpt\")\n",
    "# torch.save(atac_dataset_dpt, f = \"./data/atac_dpt.pt\")\n",
    "# torch.save(rna_dataset_dpt, f = \"./data/rna_dpt.pt\")\n",
    "atac_dataset_dpt = torch.load(f = \"./data/atac_dpt.pt\")\n",
    "rna_dataset_dpt = torch.load(f = \"./data/rna_dpt.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atac_dataset_dpt = testgraphdata(None, 10)\n",
    "# rna_dataset_dpt = testgraphdata(None, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gvae = aligned_gvae(feature1_dim = rna_dataset_diffmap['X'].shape[1], feature2_dim = atac_dataset_diffmap['X'].shape[1], hidden_dim1 = 128, hidden_dim2 = 32, hidden_dim3 = 2, dropout = 0., use_mlp = False, decoder = \"distance\")\n",
    "\n",
    "# optimizer = optim.Adam(gvae.parameters(), lr=1e-2, weight_decay=0.01)\n",
    "# gvae.train()\n",
    "# gvae.reset_parameters()\n",
    "\n",
    "# for epoch in range(0, 60):\n",
    "\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     dist_rna, dist_atac, latent_rna, latent_atac, logvar_rna, logvar_atac = gvae(rna_dataset_diffmap['X'], atac_dataset_diffmap['X'], rna_dataset_diffmap['similarity'], atac_dataset_diffmap['similarity'])\n",
    "\n",
    "#     loss, loss_align, loss_dist_atac,  loss_dist_rna, kl_atac, kl_rna = gvae_loss(latent1 = latent_rna, latent2 = latent_atac, adj1 = rna_dataset_diffmap['adj'], adj2 = atac_dataset_diffmap['adj'], recon_adj1 = dist_rna, recon_adj2 = dist_atac, logvar_latent1 = logvar_rna, logvar_latent2 = logvar_atac, lamb_align = 0, lamb_kl = 0, dist_loss_type = \"cosine\")\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     # print(latent_rna)\n",
    "\n",
    "#     if epoch % 10 == 0:\n",
    "#         log = \"Epoch: {:03d}, Total loss: {:.5f}, loss align {:.5f}, Dist RNA loss {:.5f}, Dist ATAC loss {:.5f}, KL atac loss: {:.5f}, KL rna loss: {:.5f}\"\n",
    "#         print(log.format(epoch, loss, loss_align, loss_dist_atac, loss_dist_rna, kl_atac, kl_rna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(latent1, latent2, adj1, adj2, recon_adj1, recon_adj2, lamb_align = 0.01):\n",
    "\n",
    "    loss_align = lamb_align * torch.norm(latent1 - latent2, p = 'fro')\n",
    "    \n",
    "    \n",
    "    adj1 = adj1 ** 2\n",
    "    adj2 = adj2 ** 2\n",
    "    adj1 = (adj1 / torch.norm(adj1, p = 'fro')) \n",
    "    adj2 = (adj2 / torch.norm(adj2, p = 'fro')) \n",
    "    recon_1 = (recon_adj1 / torch.norm(recon_adj1, p = \"fro\"))\n",
    "    recon_2 = (recon_adj2 / torch.norm(recon_adj2, p = \"fro\")) \n",
    "\n",
    "    # mse approx, mse loss change sqrt with mean from norm loss\n",
    "#     similarity_loss1 = torch.norm(recon_adj1 - adj1, p = \"fro\") ** 2 / (adj1.shape[0] ** 2)\n",
    "#     similarity_loss2 = torch.norm(recon_adj2 - adj2, p = \"fro\") ** 2 / (adj2.shape[0] ** 2)\n",
    "#     similarity_loss1_2 = F.mse_loss(adj1.reshape(1,-1), recon_1.reshape(1,-1), reduce=\"mean\")\n",
    "#     similarity_loss2_2 = F.mse_loss(adj2.reshape(1,-1), recon_2.reshape(1,-1), reduce=\"mean\")\n",
    "    \n",
    "    similarity_loss1 = torch.norm(recon_adj1 - adj1, p = \"fro\")\n",
    "    similarity_loss2 = torch.norm(recon_adj2 - adj2, p = \"fro\")\n",
    "    \n",
    "    loss = loss_align + similarity_loss1 + similarity_loss2 \n",
    "    \n",
    "    return loss, loss_align, similarity_loss1,  similarity_loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use distance matrix\n",
    "\n",
    "gae = curr_gae(feature1_dim = rna_dataset_dpt['X'].shape[1], \n",
    "               feature2_dim = atac_dataset_dpt['X'].shape[1], \n",
    "               hidden_dim1 = 128, hidden_dim2 = 32, hidden_dim3 = 2, dropout = 0.)\n",
    "\n",
    "optimizer = optim.Adam(gae.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "gae.train()\n",
    "gae.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Total loss: 3.47641, loss align 1.47398, Dist RNA loss 1.00125, Dist ATAC loss 1.00118\n",
      "Epoch: 010, Total loss: 3.25998, loss align 1.25767, Dist RNA loss 1.00096, Dist ATAC loss 1.00135\n",
      "Epoch: 020, Total loss: 4.20955, loss align 2.20734, Dist RNA loss 1.00104, Dist ATAC loss 1.00117\n",
      "Epoch: 030, Total loss: 3.97806, loss align 1.97613, Dist RNA loss 1.00085, Dist ATAC loss 1.00108\n",
      "Epoch: 040, Total loss: 4.16220, loss align 2.16022, Dist RNA loss 1.00031, Dist ATAC loss 1.00167\n",
      "Epoch: 050, Total loss: 3.68893, loss align 1.68748, Dist RNA loss 1.00031, Dist ATAC loss 1.00114\n",
      "Epoch: 060, Total loss: 3.12239, loss align 1.12166, Dist RNA loss 1.00016, Dist ATAC loss 1.00056\n",
      "Epoch: 070, Total loss: 4.33767, loss align 2.33645, Dist RNA loss 0.99997, Dist ATAC loss 1.00125\n",
      "Epoch: 080, Total loss: 3.00484, loss align 1.00460, Dist RNA loss 1.00001, Dist ATAC loss 1.00024\n",
      "Epoch: 090, Total loss: 3.15522, loss align 1.15511, Dist RNA loss 1.00006, Dist ATAC loss 1.00005\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(0, 100):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    dist_rna, dist_atac, latent_rna, latent_atac = gae(rna_dataset_dpt['X'], atac_dataset_dpt['X'], \n",
    "                                                       rna_dataset_dpt['similarity'], atac_dataset_dpt['similarity'])\n",
    "\n",
    "    # loss, loss_align, loss_dist_atac,  loss_dist_rna = gae_loss(latent1 = latent_rna, latent2 = latent_atac, adj1 = rna_dataset_diffmap['adj'], adj2 = atac_dataset_diffmap['adj'], recon_adj1 = dist_rna, recon_adj2 = dist_atac, lamb_align = 1e-3, dist_loss_type = \"mse\")\n",
    "\n",
    "    loss, loss_align, loss_dist_atac,  loss_dist_rna = mse_loss(latent1 = latent_rna, latent2 = latent_atac, \n",
    "                                                                adj1 = rna_dataset_dpt['adj'], \n",
    "                                                                adj2 = atac_dataset_dpt['adj'], \n",
    "                                                                recon_adj1 = dist_rna, recon_adj2 = dist_atac, \n",
    "                                                                lamb_align = 100)\n",
    "    loss.backward()\n",
    "    \n",
    "    # print(latent_rna)\n",
    "    \n",
    "    if epoch % 10 == 0 or epoch == 0:\n",
    "        log = \"Epoch: {:03d}, Total loss: {:.5f}, loss align {:.5f}, Dist RNA loss {:.5f}, Dist ATAC loss {:.5f}\"\n",
    "        print(log.format(epoch, loss, loss_align, loss_dist_atac, loss_dist_rna))\n",
    "        \n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gae.state_dict(), \"gae_best.ptH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fefaaf16ed0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gae.eval()\n",
    "dist_rna, dist_atac, latent_rna, latent_atac = gae(rna_dataset_dpt['X'], atac_dataset_dpt['X'], \n",
    "                                                   rna_dataset_dpt['similarity'], atac_dataset_dpt['similarity'])\n",
    "\n",
    "z1 = 1e5* latent_rna.detach().cpu().numpy()\n",
    "z2 = 1e5* latent_atac.detach().cpu().numpy()\n",
    "\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(z2[:,0], z2[:,1], c = np.arange(rna_dataset_diffmap['X'].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.     ,  699.4187 ,  858.73157, 2066.9932 ], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020515088"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(z2 - z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('dnn': conda)",
   "language": "python",
   "name": "python37664bitdnncondaf545b23edf394072b06b772933f9fcfb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
